{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and building vectors for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns=10\n",
    "# random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from glcdataset import build_environmental_data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499 occurrences in the dataset\n",
      "505 number of species\n",
      "\n",
      "30 entries observed at interfering locations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>glc19SpId</th>\n",
       "      <th>scName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>6.724279</td>\n",
       "      <td>47.59021</td>\n",
       "      <td>30905</td>\n",
       "      <td>Datura stramonium L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>4.462297</td>\n",
       "      <td>49.17102</td>\n",
       "      <td>33024</td>\n",
       "      <td>Euphorbia marginata Pursh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2.277133</td>\n",
       "      <td>48.81010</td>\n",
       "      <td>30144</td>\n",
       "      <td>Geum urbanum L.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Longitude  Latitude  glc19SpId                     scName\n",
       "1746   6.724279  47.59021      30905       Datura stramonium L.\n",
       "1935   4.462297  49.17102      33024  Euphorbia marginata Pursh\n",
       "311    2.277133  48.81010      30144            Geum urbanum L."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# working on a subset of Pl@ntNet Trusted: 2500 occurrences\n",
    "df = pd.read_csv('example_occurrences.csv',\n",
    "             sep=';', header='infer', quotechar='\"', low_memory=True)\n",
    "\n",
    "df = df[['Longitude','Latitude','glc19SpId','scName']]\\\n",
    "       .dropna(axis=0, how='all')\\\n",
    "       .astype({'glc19SpId': 'int64'})\n",
    "\n",
    "# target pandas series of the species identifiers (there are 505 labels)\n",
    "target_df = df['glc19SpId']\n",
    "# correspondence table between ids and the species taxonomic names\n",
    "# (Taxref names with year of discoverie)\n",
    "# taxonomic_names = pd.read_csv('../data/occurrences/taxaName_glc19SpId.csv',\n",
    "#                              sep=';',header='infer', quotechar='\"',low_memory=True)\n",
    "print(len(df), 'occurrences in the dataset')\n",
    "print(len(target_df.unique()), 'number of species\\n')\n",
    "duplicated_df = df[df.duplicated(subset=['Latitude','Longitude'],keep=False)]\n",
    "print(f'{len(duplicated_df)} entries observed at interfering locations')\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of two interfering examples: at index 383 and index 1200: lat,lng =(44.978460,-1.075745) and species ids = 31867 (Arenaria montana L.) and 31734 (Tuberaria guttata (L.) Fourr.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the environmental data: concatenated (lat,lng)+ environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>alti</th>\n",
       "      <th>awc_top</th>\n",
       "      <th>bs_top</th>\n",
       "      <th>...</th>\n",
       "      <th>etp</th>\n",
       "      <th>oc_top</th>\n",
       "      <th>pd_top</th>\n",
       "      <th>proxi_eau_fast</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.118889</td>\n",
       "      <td>43.95195</td>\n",
       "      <td>189.375</td>\n",
       "      <td>165.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1219.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.592500</td>\n",
       "      <td>45.10639</td>\n",
       "      <td>45.625</td>\n",
       "      <td>120.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.534861</td>\n",
       "      <td>48.38958</td>\n",
       "      <td>69.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>800.625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude     alti  awc_top  bs_top  ...       etp  oc_top  \\\n",
       "0  2.118889   43.95195  189.375    165.0    85.0  ...  1219.375     1.0   \n",
       "1 -0.592500   45.10639   45.625    120.0    35.0  ...  1140.625     1.0   \n",
       "2 -4.534861   48.38958   69.375      0.0    85.0  ...   800.625     2.0   \n",
       "\n",
       "   pd_top  proxi_eau_fast  text  \n",
       "0     2.0             0.0   2.0  \n",
       "1     1.0             0.0   1.0  \n",
       "2     2.0             0.0   0.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    30021\n",
       "1    31997\n",
       "2    31385\n",
       "3    33228\n",
       "4    33228\n",
       "Name: glc19SpId, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building the environmental data\n",
    "env_df = build_environmental_data(df[['Latitude','Longitude']],patches_dir='example_envtensors')\n",
    "display(env_df.head(3))\n",
    "display(target_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data (numpy arrays) and scaling the data to have a mean of 0 and unit variance: this is necessary for most of ML models to work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = env_df.values\n",
    "y = target_df.values\n",
    "# Standardize the features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vector model, euclidean metric\n",
      "Top30 score:0.246\n",
      "MRR score:0.05718168788586186\n",
      "Params: {'metric': 'euclidean', 'ranking_size': 30}\n",
      "\n",
      "Test vector model, cosine metric\n",
      "Top30 score:0.258\n",
      "MRR score:0.057060165142736534\n",
      "Params: {'metric': 'cosine', 'ranking_size': 30}\n"
     ]
    }
   ],
   "source": [
    "from vector_model import VectorModel\n",
    "# Evaluate as the average accuracy on one train/split random sample:\n",
    "print(\"Test vector model, euclidean metric\")\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "classifier = VectorModel(metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "print(f'Top30 score:{classifier.top30_score(y_predicted, y_test)}')\n",
    "print(f'MRR score:{classifier.mrr_score(y_predicted, y_test)}')\n",
    "print('Params:',classifier.get_params())\n",
    "\n",
    "print(\"\\nTest vector model, cosine metric\")\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "classifier = VectorModel(metric='cosine')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "print(f'Top30 score:{classifier.top30_score(y_predicted, y_test)}')\n",
    "print(f'MRR score:{classifier.mrr_score(y_predicted, y_test)}')\n",
    "print('Params:',classifier.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test KNN model, uniform weights\n",
      "Top30 score:0.27\n",
      "MRR score:0.058909794847547436\n",
      "Params: {'metric': 'minkowski', 'n_neighbors': 150, 'p': None, 'ranking_size': 30, 'weights': 'uniform'}\n",
      "\n",
      "Test KNN model, distance weights\n",
      "Top30 score:0.268\n",
      "MRR score:0.05116993690634731\n",
      "Params: {'metric': 'minkowski', 'n_neighbors': 150, 'p': None, 'ranking_size': 30, 'weights': 'distance'}\n",
      "\n",
      "Example of predict proba:\n",
      "occurrence:\n",
      "[ 0.04019058  1.08806812 -0.32832856  1.03770293  0.65384761 -0.73433122\n",
      " -0.56597094 -0.54729947 -0.46501198 -0.44076546 -0.88653399  0.38336852\n",
      " -0.98292161 -0.9797477   0.35280841  0.56206479 -0.36632291  0.55868843\n",
      "  0.31648711 -0.04025585  0.04143279 -0.6445334   0.55454116 -0.94042465\n",
      " -1.56363946 -0.79182766  1.41840965 -1.7189894   0.28012152  0.75700134\n",
      " -0.03892492 -0.8874651   1.01713738 -0.34948162  0.94649875]\n",
      "predicted labels:\n",
      "[[30025 33042 32516 30683 29979 30003 30463 29980 30591 31347 30363 31218\n",
      "  33900 30750 30728 32668 29981 30634 30905 30184 30425 31453 30925 30295\n",
      "  32166 29972 30922 30752 31966 30123]]\n",
      "predicted probas:\n",
      "[[0.04551758 0.04281197 0.03278503 0.02429859 0.02418445 0.02228156\n",
      "  0.01708759 0.01666886 0.01598609 0.01469303 0.01445123 0.0142533\n",
      "  0.0141375  0.01361346 0.01359796 0.01323526 0.01314205 0.01309255\n",
      "  0.01284453 0.01271198 0.01246656 0.01214725 0.01192603 0.01159498\n",
      "  0.01128042 0.01116537 0.01099376 0.01090372 0.01067057 0.01019214]]\n"
     ]
    }
   ],
   "source": [
    "from knn_model import KNearestNeighborsModel\n",
    "\n",
    "# Evaluate as the average accuracy on one train/split random sample:\n",
    "print(\"Test KNN model, uniform weights\")\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "classifier = KNearestNeighborsModel(n_neighbors=150, weights='uniform')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "print(f'Top30 score:{classifier.top30_score(y_predicted, y_test)}')\n",
    "print(f'MRR score:{classifier.mrr_score(y_predicted, y_test)}')\n",
    "print('Params:',classifier.get_params())\n",
    "\n",
    "print(\"\\nTest KNN model, distance weights\")\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "classifier = KNearestNeighborsModel(n_neighbors=150, weights='distance')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "print(f'Top30 score:{classifier.top30_score(y_predicted, y_test)}')\n",
    "print(f'MRR score:{classifier.mrr_score(y_predicted, y_test)}')\n",
    "print('Params:',classifier.get_params())\n",
    "\n",
    "print(\"\\nExample of predict proba:\")\n",
    "print(f\"occurrence:\\n{X_test[12]}\")\n",
    "y_pred, y_probas = classifier.predict(X_test[12].reshape(1,-1), return_proba=True)\n",
    "print(f'predicted labels:\\n{y_pred}')\n",
    "print(f'predicted probas:\\n{y_probas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ClusteringModel():\n",
    "\n",
    "    def _load_data(self, sklearn_load_ds):\n",
    "        \n",
    "        data = sklearn_load_ds\n",
    "        X = pd.DataFrame(data.data)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "    def __init__(self, sklearn_load_ds):\n",
    "        self._load_data(sklearn_load_ds)\n",
    "\n",
    "    def classify(self, model=LogisticRegression(random_state=42)):\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        print('Accuracy: {}'.format(accuracy_score(self.y_test, y_pred)))\n",
    "\n",
    "    def clusterize(self, output='add'):\n",
    "        n_clusters = len(np.unique(self.y_train))\n",
    "        clf = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "        clf.fit(self.X_train)\n",
    "        y_labels_train = clf.labels_\n",
    "        y_labels_test = clf.predict(self.X_test)\n",
    "        if output == 'add':\n",
    "            self.X_train['km_clust'] = y_labels_train\n",
    "            self.X_test['km_clust'] = y_labels_test\n",
    "        elif output == 'replace':\n",
    "            self.X_train = y_labels_train[:, np.newaxis]\n",
    "            self.X_test = y_labels_test[:, np.newaxis]\n",
    "        else:\n",
    "            raise ValueError('output should be either add or replace')\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
